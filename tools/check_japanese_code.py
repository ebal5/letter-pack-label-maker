#!/usr/bin/env python3
"""
æ—¥æœ¬èªã‚³ãƒ¼ãƒ‰å“è³ªãƒã‚§ãƒƒã‚«ãƒ¼

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€æ—¥æœ¬èªã‚³ãƒ¼ãƒ‰ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€æ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«ï¼‰ã®å“è³ªã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚
ä»¥ä¸‹ã®é …ç›®ã‚’ãƒã‚§ãƒƒã‚¯ï¼š
1. æ–‡å­—ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆUTF-8ã‹ã©ã†ã‹ï¼‰
2. å…¨è§’ãƒ»åŠè§’ã®çµ±ä¸€
3. docstringã®å……å®Ÿåº¦
"""

import re
import sys
from pathlib import Path


def check_encoding(file_path: Path) -> tuple[str, bool]:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ãƒã‚§ãƒƒã‚¯"""
    try:
        with open(file_path, encoding="utf-8") as f:
            f.read()
        return "UTF-8", True
    except UnicodeDecodeError:
        # ãã®ä»–ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦ã™
        for encoding in ["shift_jis", "euc_jp", "iso2022_jp"]:
            try:
                with open(file_path, encoding=encoding) as f:
                    f.read()
                return encoding, False
            except UnicodeDecodeError:
                continue
        return "Unknown", False


def check_fullwidth_numbers(text: str, file_path: str, line_num: int) -> list[dict]:
    """å…¨è§’æ•°å­—ã‚’ãƒã‚§ãƒƒã‚¯"""
    issues = []
    # å…¨è§’æ•°å­—ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆï¼-ï¼™ï¼‰
    fullwidth_pattern = re.compile(r"[ï¼-ï¼™]+")

    for match in fullwidth_pattern.finditer(text):
        # ã‚³ãƒ¡ãƒ³ãƒˆå†…ã‹ã‚³ãƒ¼ãƒ‰å†…ã‹ã¯åŒºåˆ¥ã—ãªã„ï¼ˆã™ã¹ã¦æ¤œå‡ºï¼‰
        halfwidth = match.group().translate(str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™", "0123456789"))
        issues.append(
            {
                "file": file_path,
                "line": line_num,
                "type": "å…¨è§’æ•°å­—",
                "current": match.group(),
                "suggested": halfwidth,
            }
        )

    return issues


def check_fullwidth_alpha(text: str, file_path: str, line_num: int) -> list[dict]:
    """å…¨è§’è‹±å­—ã‚’ãƒã‚§ãƒƒã‚¯"""
    issues = []
    # å…¨è§’è‹±å­—ãƒ‘ã‚¿ãƒ¼ãƒ³
    fullwidth_pattern = re.compile(r"[ï¼¡-ï¼ºï½-ï½š]+")

    for match in fullwidth_pattern.finditer(text):
        halfwidth = match.group().translate(
            str.maketrans(
                "ï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§ï¼¨ï¼©ï¼ªï¼«ï¼¬ï¼­ï¼®ï¼¯ï¼°ï¼±ï¼²ï¼³ï¼´ï¼µï¼¶ï¼·ï¼¸ï¼¹ï¼ºï½ï½‚ï½ƒï½„ï½…ï½†ï½‡ï½ˆï½‰ï½Šï½‹ï½Œï½ï½ï½ï½ï½‘ï½’ï½“ï½”ï½•ï½–ï½—ï½˜ï½™ï½š",
                "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz",
            )
        )
        issues.append(
            {
                "file": file_path,
                "line": line_num,
                "type": "å…¨è§’è‹±å­—",
                "current": match.group(),
                "suggested": halfwidth,
            }
        )

    return issues


def check_docstrings(file_path: Path) -> list[dict]:
    """docstringã®æœ‰ç„¡ã‚’ãƒã‚§ãƒƒã‚¯"""
    issues = []

    try:
        with open(file_path, encoding="utf-8") as f:
            content = f.read()
    except (OSError, UnicodeDecodeError):
        return issues

    # é–¢æ•°å®šç¾©ã‚’æ¤œç´¢
    function_pattern = re.compile(r"^def\s+(\w+)\s*\(", re.MULTILINE)
    class_pattern = re.compile(r"^class\s+(\w+)", re.MULTILINE)

    # é–¢æ•°ã‚’ãƒã‚§ãƒƒã‚¯
    for match in function_pattern.finditer(content):
        func_name = match.group(1)
        # ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆé–¢æ•°ã¨ãƒã‚¸ãƒƒã‚¯ãƒ¡ã‚½ãƒƒãƒ‰ã¯é™¤å¤–
        if not func_name.startswith("_"):
            # docstringãŒã‚ã‚‹ã‹ç¢ºèªï¼ˆç°¡æ˜“ãƒã‚§ãƒƒã‚¯ï¼‰
            search_start = match.end()
            next_200 = content[search_start : search_start + 300]

            if '"""' not in next_200 and "'''" not in next_200:
                # è¡Œç•ªå·ã‚’è¨ˆç®—
                line_num = content[: match.start()].count("\n") + 1
                issues.append(
                    {
                        "file": str(file_path),
                        "line": line_num,
                        "type": "docstringä¸è¶³",
                        "target": f"é–¢æ•° {func_name}",
                    }
                )

    # ã‚¯ãƒ©ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯
    for match in class_pattern.finditer(content):
        class_name = match.group(1)
        # ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã‚¯ãƒ©ã‚¹ã¯é™¤å¤–
        if not class_name.startswith("_"):
            search_start = match.end()
            next_300 = content[search_start : search_start + 500]

            if '"""' not in next_300 and "'''" not in next_300:
                line_num = content[: match.start()].count("\n") + 1
                issues.append(
                    {
                        "file": str(file_path),
                        "line": line_num,
                        "type": "docstringä¸è¶³",
                        "target": f"ã‚¯ãƒ©ã‚¹ {class_name}",
                    }
                )

    return issues


def generate_report(
    encoding_issues: list[tuple],
    fullwidth_issues: list[dict],
    docstring_issues: list[dict],
) -> None:
    """ãƒã‚§ãƒƒã‚¯çµæœã‚’ãƒ¬ãƒãƒ¼ãƒˆå½¢å¼ã§å‡ºåŠ›"""
    print("\n" + "=" * 60)
    print("ğŸ” æ—¥æœ¬èªã‚³ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯ãƒ¬ãƒãƒ¼ãƒˆ")
    print("=" * 60 + "\n")

    # 1. ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒã‚§ãƒƒã‚¯
    print("ã€æ–‡å­—ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€‘")
    if not encoding_issues:
        print("âœ… ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒUTF-8ã§ã™\n")
    else:
        print(f"âŒ {len(encoding_issues)}ä»¶ã®å•é¡Œã‚’æ¤œå‡º\n")
        for file_path, encoding in encoding_issues:
            print(f"  âŒ {file_path}: {encoding}")
        print()

    # 2. å…¨è§’ãƒ»åŠè§’ãƒã‚§ãƒƒã‚¯
    print("ã€å…¨è§’ãƒ»åŠè§’ã®ä½¿ã„åˆ†ã‘ã€‘")
    if not fullwidth_issues:
        print("âœ… å•é¡Œã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ\n")
    else:
        print(f"âš ï¸ {len(fullwidth_issues)}ä»¶ã®å•é¡Œã‚’æ¤œå‡º\n")
        # æœ€åˆã®10ä»¶ã®ã¿è¡¨ç¤º
        for issue in fullwidth_issues[:10]:
            print(f"  {issue['file']}:{issue['line']}")
            print(f"    - å•é¡Œ: {issue['type']}")
            print(f"    - ç¾åœ¨: {issue['current']}")
            print(f"    - æ¨å¥¨: {issue['suggested']}")
        if len(fullwidth_issues) > 10:
            print(f"\n  ... ãã®ä»– {len(fullwidth_issues) - 10}ä»¶")
        print()

    # 3. docstringãƒã‚§ãƒƒã‚¯
    print("ã€ã‚³ãƒ¡ãƒ³ãƒˆãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€‘")
    if not docstring_issues:
        print("âœ… ã™ã¹ã¦ã®å…¬é–‹é–¢æ•°ãƒ»ã‚¯ãƒ©ã‚¹ã«é©åˆ‡ãªdocstringãŒã‚ã‚Šã¾ã™\n")
    else:
        print(f"âš ï¸ {len(docstring_issues)}ä»¶ã®docstringä¸è¶³ã‚’æ¤œå‡º\n")
        # æœ€åˆã®10ä»¶ã®ã¿è¡¨ç¤º
        for issue in docstring_issues[:10]:
            print(f"  {issue['file']}:{issue['line']}")
            print(f"    - {issue['target']}: docstringãŒã‚ã‚Šã¾ã›ã‚“")
        if len(docstring_issues) > 10:
            print(f"\n  ... ãã®ä»– {len(docstring_issues) - 10}ä»¶")
        print()

    # ç·åˆè©•ä¾¡
    total_issues = len(encoding_issues) + len(fullwidth_issues) + len(docstring_issues)
    print("ã€ç·åˆè©•ä¾¡ã€‘")
    if total_issues == 0:
        print("âœ… ã™ã¹ã¦ã®ãƒã‚§ãƒƒã‚¯ã«åˆæ ¼ã—ã¾ã—ãŸï¼")
    else:
        print(f"âš ï¸ {total_issues}ä»¶ã®æ”¹å–„ç‚¹ãŒã‚ã‚Šã¾ã™")
        if encoding_issues:
            print(f"  - æ–‡å­—ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {len(encoding_issues)}ä»¶ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¤‰æ›´ãŒå¿…è¦ï¼‰")
        if fullwidth_issues:
            print(f"  - å…¨è§’ãƒ»åŠè§’: {len(fullwidth_issues)}ä»¶ï¼ˆä¿®æ­£å¯èƒ½ï¼‰")
        if docstring_issues:
            print(f"  - docstring: {len(docstring_issues)}ä»¶ï¼ˆè¿½åŠ ãŒå¿…è¦ï¼‰")

    print("\n" + "=" * 60 + "\n")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³
    patterns = [
        ("*.py", "Pythonãƒ•ã‚¡ã‚¤ãƒ«"),
        ("*.md", "Markdownãƒ•ã‚¡ã‚¤ãƒ«"),
        ("*.html", "HTMLãƒ•ã‚¡ã‚¤ãƒ«"),
    ]

    encoding_issues = []
    fullwidth_issues = []
    docstring_issues = []

    # 1. ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒã‚§ãƒƒã‚¯
    print("\nğŸ” ãƒã‚§ãƒƒã‚¯ä¸­...\n")
    print("  - æ–‡å­—ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")

    project_root = Path(".")
    for pattern, _ in patterns:
        for file_path in project_root.rglob(pattern):
            # é™¤å¤–ãƒ•ã‚¡ã‚¤ãƒ«
            if any(
                x in str(file_path)
                for x in [".git", "node_modules", ".venv", "__pycache__", "uv.lock"]
            ):
                continue

            encoding, is_utf8 = check_encoding(file_path)
            if not is_utf8:
                encoding_issues.append((file_path, encoding))

    # 2. Pythonãƒ•ã‚¡ã‚¤ãƒ«ã®å…¨è§’ãƒ»åŠè§’ãƒã‚§ãƒƒã‚¯
    print("  - å…¨è§’ãƒ»åŠè§’ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
    for file_path in project_root.rglob("*.py"):
        if any(x in str(file_path) for x in [".git", "node_modules", ".venv", "__pycache__"]):
            continue

        try:
            with open(file_path, encoding="utf-8") as f:
                for i, line in enumerate(f, 1):
                    # ã‚³ãƒ¡ãƒ³ãƒˆã¨æ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«ã‹ã‚‰æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
                    if "#" in line or '"' in line or "'" in line:
                        fullwidth_issues.extend(check_fullwidth_numbers(line, str(file_path), i))
                        fullwidth_issues.extend(check_fullwidth_alpha(line, str(file_path), i))
        except (OSError, UnicodeDecodeError):
            pass

    # 3. Pythonãƒ•ã‚¡ã‚¤ãƒ«ã®docstringãƒã‚§ãƒƒã‚¯
    print("  - docstringã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
    for file_path in project_root.rglob("*.py"):
        if any(
            x in str(file_path) for x in [".git", "node_modules", ".venv", "__pycache__", "tests"]
        ):
            continue

        docstring_issues.extend(check_docstrings(file_path))

    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    generate_report(encoding_issues, fullwidth_issues, docstring_issues)

    # çµ‚äº†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
    return 0 if not encoding_issues else 1


if __name__ == "__main__":
    sys.exit(main())
