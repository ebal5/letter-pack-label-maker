#!/usr/bin/env python3
"""
Deployment Verification Tool

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€Letter Pack Label Makerã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚’æ¤œè¨¼ã—ã¾ã™ã€‚
GitHub Pagesã€Dockerç’°å¢ƒã€ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã®3ã¤ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæ–¹æ³•ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚
"""

from __future__ import annotations

import argparse
import asyncio
import sys
import time
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any

import yaml

try:
    from playwright.async_api import async_playwright
except ImportError:
    print("Warning: Playwright not installed. Install with: uv run playwright install chromium")
    async_playwright = None

try:
    import requests
except ImportError:
    print("Warning: requests not installed. Install with: uv pip install requests")
    requests = None

try:
    from bs4 import BeautifulSoup
except ImportError:
    print("Warning: BeautifulSoup not installed. Install with: uv pip install beautifulsoup4")
    BeautifulSoup = None


@dataclass
class LinkCheckResult:
    """ãƒªãƒ³ã‚¯ãƒã‚§ãƒƒã‚¯ã®çµæœ"""

    url: str
    status: int | None
    ok: bool
    error: str | None = None
    is_external: bool = False


@dataclass
class VerificationResult:
    """æ¤œè¨¼çµæœã®åŸºæœ¬ã‚¯ãƒ©ã‚¹"""

    success: bool
    message: str
    details: dict[str, Any] = field(default_factory=dict)
    errors: list[str] = field(default_factory=list)
    warnings: list[str] = field(default_factory=list)
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())


@dataclass
class GitHubPagesVerificationResult(VerificationResult):
    """GitHub Pagesæ¤œè¨¼ã®çµæœ"""

    accessible: bool = False
    status_code: int | None = None
    page_load_time_ms: float | None = None
    pyodide_init_time_ms: float | None = None
    critical_elements_found: list[str] = field(default_factory=list)
    critical_elements_missing: list[str] = field(default_factory=list)
    link_check_results: list[LinkCheckResult] = field(default_factory=list)


@dataclass
class DockerVerificationResult(VerificationResult):
    """Dockeræ¤œè¨¼ã®çµæœ"""

    build_success: bool = False
    image_id: str | None = None
    image_size_mb: float | None = None
    container_started: bool = False
    health_check_passed: bool = False
    health_check_time_ms: float | None = None
    fonts_available: list[str] = field(default_factory=list)
    web_server_responding: bool = False


class DeploymentVerifier:
    """ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæ¤œè¨¼ã®åŸºæœ¬ã‚¯ãƒ©ã‚¹"""

    def __init__(self, config_path: str | Path | None = None):
        """åˆæœŸåŒ–

        Args:
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã€‚Noneã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨
        """
        if config_path is None:
            config_path = (
                Path(__file__).parent.parent / ".claude/skills/deployment-verification/config.yaml"
            )
        else:
            config_path = Path(config_path)

        if config_path.exists():
            with open(config_path, encoding="utf-8") as f:
                self.config = yaml.safe_load(f)
        else:
            print(f"Warning: Config file not found at {config_path}, using defaults")
            self.config = self._get_default_config()

        self.debug = self.config.get("debug", {}).get("enabled", False)

    def _get_default_config(self) -> dict[str, Any]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’è¿”ã™"""
        return {
            "github_pages": {
                "production_url": "https://ebal5.github.io/letter-pack-label-maker/",
                "performance_thresholds": {
                    "page_load_ms": 3000,
                    "pyodide_init_ms": 90000,
                },
            },
            "docker": {
                "image_name": "letterpack-web",
                "health_check_timeout": 30,
            },
        }

    def _log(self, message: str, level: str = "INFO"):
        """ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡ºåŠ›

        Args:
            message: ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            level: ãƒ­ã‚°ãƒ¬ãƒ™ãƒ« (INFO, WARNING, ERROR, DEBUG)
        """
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        if level == "DEBUG" and not self.debug:
            return
        print(f"[{timestamp}] [{level}] {message}")


class GitHubPagesVerifier(DeploymentVerifier):
    """GitHub Pagesæ¤œè¨¼ã‚¯ãƒ©ã‚¹"""

    async def verify(
        self, check_links: bool = True, measure_performance: bool = True
    ) -> GitHubPagesVerificationResult:
        """GitHub Pagesã‚’æ¤œè¨¼

        Args:
            check_links: ãƒªãƒ³ã‚¯ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ã‹
            measure_performance: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è¨ˆæ¸¬ã™ã‚‹ã‹

        Returns:
            æ¤œè¨¼çµæœ
        """
        self._log("Starting GitHub Pages verification")

        result = GitHubPagesVerificationResult(success=False, message="Verification started")

        if async_playwright is None:
            result.errors.append(
                "Playwright not installed. Install with: uv run playwright install chromium"
            )
            result.message = "Verification failed: Missing dependencies"
            return result

        config = self.config.get("github_pages", {})
        url = config.get("production_url")

        if not url:
            result.errors.append("production_url not configured")
            result.message = "Verification failed: Missing configuration"
            return result

        try:
            async with async_playwright() as p:
                browser = await p.chromium.launch()
                page = await browser.new_page()

                # ãƒšãƒ¼ã‚¸ã‚¢ã‚¯ã‚»ã‚¹
                self._log(f"Accessing {url}")
                start_time = time.time()

                try:
                    response = await page.goto(url, wait_until="domcontentloaded")
                    page_load_time = (time.time() - start_time) * 1000

                    result.status_code = response.status if response else None
                    result.accessible = response and response.ok
                    result.page_load_time_ms = page_load_time

                    if result.accessible:
                        self._log(
                            f"âœ… Page accessible (HTTP {result.status_code}, {page_load_time:.0f}ms)"
                        )
                    else:
                        self._log(
                            f"âŒ Page not accessible (HTTP {result.status_code})",
                            "ERROR",
                        )
                        result.errors.append(f"HTTP {result.status_code}")

                except Exception as e:
                    self._log(f"âŒ Failed to access page: {e}", "ERROR")
                    result.errors.append(f"Page access failed: {e}")
                    await browser.close()
                    result.message = "Verification failed: Page access error"
                    return result

                # å¿…é ˆè¦ç´ ã®ãƒã‚§ãƒƒã‚¯
                critical_elements = config.get("critical_elements", [])
                if critical_elements:
                    self._log("Checking critical elements")
                    await self._check_critical_elements(page, critical_elements, result)

                # ãƒªãƒ³ã‚¯ãƒã‚§ãƒƒã‚¯
                if check_links:
                    self._log("Checking links")
                    link_results = await self._check_links(page, url, config)
                    result.link_check_results = link_results

                    # ãƒªãƒ³ã‚¯ãƒã‚§ãƒƒã‚¯çµæœã®ã‚µãƒãƒªãƒ¼
                    broken_internal = [
                        lr for lr in link_results if not lr.ok and not lr.is_external
                    ]
                    broken_external = [lr for lr in link_results if not lr.ok and lr.is_external]

                    if broken_internal:
                        result.errors.append(f"Found {len(broken_internal)} broken internal links")
                    if broken_external:
                        if config.get("link_check", {}).get("external_as_warning", True):
                            result.warnings.append(
                                f"Found {len(broken_external)} broken external links"
                            )
                        else:
                            result.errors.append(
                                f"Found {len(broken_external)} broken external links"
                            )

                    self._log(
                        f"Link check: {len([lr for lr in link_results if lr.ok])} OK, "
                        f"{len(broken_internal)} broken internal, "
                        f"{len(broken_external)} broken external"
                    )

                await browser.close()

        except Exception as e:
            self._log(f"âŒ Verification failed: {e}", "ERROR")
            result.errors.append(f"Verification exception: {e}")
            result.message = "Verification failed: Unexpected error"
            return result

        # çµæœã®åˆ¤å®š
        result.success = len(result.errors) == 0
        if result.success:
            result.message = "âœ… GitHub Pages verification passed"
            self._log(result.message)
        else:
            result.message = f"âŒ GitHub Pages verification failed with {len(result.errors)} errors"
            self._log(result.message, "ERROR")

        return result

    async def _check_critical_elements(
        self,
        page,
        critical_elements: list[dict],
        result: GitHubPagesVerificationResult,
    ):
        """å¿…é ˆè¦ç´ ã‚’ãƒã‚§ãƒƒã‚¯

        Args:
            page: Playwrightã®ãƒšãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            critical_elements: ãƒã‚§ãƒƒã‚¯ã™ã‚‹è¦ç´ ã®ãƒªã‚¹ãƒˆ
            result: çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        for element in critical_elements:
            selector = element.get("selector")
            description = element.get("description", selector)
            timeout = element.get("timeout_ms", 5000)

            try:
                await page.wait_for_selector(selector, timeout=timeout)
                result.critical_elements_found.append(description)
                self._log(f"  âœ… {description}: Found")
            except Exception:
                result.critical_elements_missing.append(description)
                result.errors.append(f"Critical element not found: {description}")
                self._log(f"  âŒ {description}: Not found", "ERROR")

    async def _check_links(self, page, base_url: str, config: dict) -> list[LinkCheckResult]:
        """ãƒšãƒ¼ã‚¸å†…ã®ãƒªãƒ³ã‚¯ã‚’ãƒã‚§ãƒƒã‚¯

        Args:
            page: Playwrightã®ãƒšãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            base_url: ãƒ™ãƒ¼ã‚¹URL
            config: è¨­å®š

        Returns:
            ãƒªãƒ³ã‚¯ãƒã‚§ãƒƒã‚¯çµæœã®ãƒªã‚¹ãƒˆ
        """
        link_config = config.get("link_check", {})
        ignore_patterns = link_config.get("ignore_patterns", [])
        timeout_seconds = link_config.get("timeout_seconds", 10)

        # ãƒšãƒ¼ã‚¸å†…ã®ã™ã¹ã¦ã®ãƒªãƒ³ã‚¯ã‚’æŠ½å‡º
        links = await page.evaluate(
            """
            () => Array.from(document.querySelectorAll('a'))
                .map(a => a.href)
                .filter(href => href && href.trim() !== '')
        """
        )

        # é‡è¤‡ã‚’å‰Šé™¤
        unique_links = list(set(links))
        results = []

        for link in unique_links:
            # ç„¡è¦–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒã‚§ãƒƒã‚¯
            if any(pattern in link for pattern in ignore_patterns):
                continue

            is_external = not link.startswith(base_url)

            try:
                # HEAD ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ãƒªãƒ³ã‚¯ã‚’ãƒã‚§ãƒƒã‚¯
                if requests is not None:
                    response = requests.head(link, timeout=timeout_seconds, allow_redirects=True)
                    results.append(
                        LinkCheckResult(
                            url=link,
                            status=response.status_code,
                            ok=response.ok,
                            is_external=is_external,
                        )
                    )
                else:
                    # requestsãŒãªã„å ´åˆã¯Playwrightã‚’ä½¿ç”¨
                    response = await page.request.head(link)
                    results.append(
                        LinkCheckResult(
                            url=link,
                            status=response.status,
                            ok=response.ok,
                            is_external=is_external,
                        )
                    )
            except Exception as e:
                results.append(
                    LinkCheckResult(
                        url=link,
                        status=None,
                        ok=False,
                        error=str(e),
                        is_external=is_external,
                    )
                )

        return results


class DockerVerifier(DeploymentVerifier):
    """Dockerç’°å¢ƒæ¤œè¨¼ã‚¯ãƒ©ã‚¹"""

    def verify(self, build_image: bool = True) -> DockerVerificationResult:
        """Dockerç’°å¢ƒã‚’æ¤œè¨¼

        Args:
            build_image: ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰ã™ã‚‹ã‹

        Returns:
            æ¤œè¨¼çµæœ
        """
        self._log("Starting Docker verification")

        result = DockerVerificationResult(success=False, message="Verification started")

        try:
            import docker
        except ImportError:
            result.errors.append("Docker SDK not installed. Install with: uv pip install docker")
            result.message = "Verification failed: Missing dependencies"
            return result

        config = self.config.get("docker", {})

        try:
            client = docker.from_env()
            self._log("âœ… Connected to Docker daemon")
        except Exception as e:
            self._log(f"âŒ Cannot connect to Docker daemon: {e}", "ERROR")
            result.errors.append(f"Docker daemon not running: {e}")
            result.message = "Verification failed: Docker daemon error"
            return result

        # ã‚¤ãƒ¡ãƒ¼ã‚¸ã®ãƒ“ãƒ«ãƒ‰
        if build_image:
            self._log("Building Docker image")
            try:
                image_name = config.get("image_name", "letterpack-web")
                image_tag = config.get("image_tag", "latest")
                full_image_name = f"{image_name}:{image_tag}"

                # ãƒ“ãƒ«ãƒ‰
                image, build_logs = client.images.build(
                    path=str(Path(__file__).parent.parent),
                    tag=full_image_name,
                    rm=True,
                )

                result.build_success = True
                result.image_id = image.id
                result.image_size_mb = image.attrs["Size"] / (1024 * 1024)

                self._log(f"âœ… Image built: {result.image_size_mb:.2f} MB")

                # ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚µã‚¤ã‚ºã®è­¦å‘Š
                warning_threshold = config.get("image_size_warning_mb", 500)
                if result.image_size_mb > warning_threshold:
                    result.warnings.append(
                        f"Image size ({result.image_size_mb:.2f} MB) exceeds warning threshold ({warning_threshold} MB)"
                    )
                    self._log(
                        f"âš ï¸  Image size warning: {result.image_size_mb:.2f} MB",
                        "WARNING",
                    )

            except Exception as e:
                self._log(f"âŒ Image build failed: {e}", "ERROR")
                result.errors.append(f"Image build failed: {e}")
                result.message = "Verification failed: Build error"
                return result

        # ã‚³ãƒ³ãƒ†ãƒŠã®èµ·å‹•ã¨ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
        self._log("Starting container for health check")
        container = None
        try:
            container_name = config.get("container_name", "letterpack-web-verification-test")
            image_name = config.get("image_name", "letterpack-web")
            image_tag = config.get("image_tag", "latest")
            full_image_name = f"{image_name}:{image_tag}"

            # æ—¢å­˜ã®ãƒ†ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒŠã‚’å‰Šé™¤
            try:
                old_container = client.containers.get(container_name)
                old_container.stop()
                old_container.remove()
                self._log(f"Removed old test container: {container_name}")
            except docker.errors.NotFound:
                pass

            # ã‚³ãƒ³ãƒ†ãƒŠã‚’èµ·å‹•
            test_env = config.get("test_environment", {})
            container = client.containers.run(
                full_image_name,
                detach=True,
                name=container_name,
                ports={"5000/tcp": 5000},
                environment=test_env,
            )

            result.container_started = True
            self._log("âœ… Container started")

            # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚’å¾…ã¤
            timeout = config.get("health_check_timeout", 30)
            start_time = time.time()

            while time.time() - start_time < timeout:
                container.reload()
                state = container.attrs["State"]

                if "Health" in state:
                    health = state["Health"]["Status"]

                    if health == "healthy":
                        health_check_time = (time.time() - start_time) * 1000
                        result.health_check_passed = True
                        result.health_check_time_ms = health_check_time
                        self._log(f"âœ… Health check passed ({health_check_time:.0f}ms)")
                        break
                    elif health == "unhealthy":
                        result.errors.append("Container became unhealthy")
                        self._log("âŒ Container became unhealthy", "ERROR")
                        break
                else:
                    # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãŒå®šç¾©ã•ã‚Œã¦ã„ãªã„å ´åˆã€ã‚³ãƒ³ãƒ†ãƒŠãŒå®Ÿè¡Œä¸­ã‹ãƒã‚§ãƒƒã‚¯
                    if state.get("Running"):
                        health_check_time = (time.time() - start_time) * 1000
                        result.health_check_passed = True
                        result.health_check_time_ms = health_check_time
                        self._log(
                            f"âœ… Container running ({health_check_time:.0f}ms) [No health check defined]"
                        )
                        break

                time.sleep(1)

            if not result.health_check_passed:
                result.warnings.append(f"Health check timeout after {timeout} seconds")

        except Exception as e:
            self._log(f"âŒ Container verification failed: {e}", "ERROR")
            result.errors.append(f"Container verification failed: {e}")
        finally:
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if container:
                try:
                    container.stop()
                    container.remove()
                    self._log("Cleaned up test container")
                except Exception as e:
                    self._log(f"Warning: Failed to cleanup container: {e}", "WARNING")

        # çµæœã®åˆ¤å®š
        result.success = len(result.errors) == 0
        if result.success:
            result.message = "âœ… Docker verification passed"
            self._log(result.message)
        else:
            result.message = f"âŒ Docker verification failed with {len(result.errors)} errors"
            self._log(result.message, "ERROR")

        return result


def generate_markdown_report(results: dict[str, VerificationResult]) -> str:
    """æ¤œè¨¼çµæœã‚’Markdownãƒ¬ãƒãƒ¼ãƒˆã¨ã—ã¦ç”Ÿæˆ

    Args:
        results: æ¤œè¨¼çµæœã®è¾æ›¸

    Returns:
        Markdownãƒ¬ãƒãƒ¼ãƒˆ
    """
    lines = [
        "# Deployment Verification Report",
        "",
        f"**Generated at**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        "",
    ]

    # ã‚µãƒãƒªãƒ¼
    lines.append("## Summary")
    lines.append("")

    total_errors = sum(len(r.errors) for r in results.values())
    total_warnings = sum(len(r.warnings) for r in results.values())

    if total_errors == 0:
        lines.append("âœ… **All verifications passed**")
    else:
        lines.append(
            f"âŒ **Verification failed with {total_errors} error(s) and {total_warnings} warning(s)**"
        )

    lines.append("")

    # å„æ¤œè¨¼çµæœ
    for target, result in results.items():
        lines.append(f"## {target.title()} Verification")
        lines.append("")

        if result.success:
            lines.append("âœ… **Status**: PASSED")
        else:
            lines.append("âŒ **Status**: FAILED")

        lines.append("")

        # GitHub Pageså›ºæœ‰ã®æƒ…å ±
        if isinstance(result, GitHubPagesVerificationResult):
            lines.append("### Details")
            lines.append("")
            lines.append(f"- **Accessible**: {'âœ… Yes' if result.accessible else 'âŒ No'}")
            lines.append(f"- **Status Code**: {result.status_code}")
            if result.page_load_time_ms:
                lines.append(f"- **Page Load Time**: {result.page_load_time_ms:.0f} ms")
            if result.pyodide_init_time_ms:
                lines.append(f"- **Pyodide Init Time**: {result.pyodide_init_time_ms:.0f} ms")
            lines.append("")

            if result.critical_elements_found:
                lines.append("### Critical Elements Found")
                lines.append("")
                for element in result.critical_elements_found:
                    lines.append(f"- âœ… {element}")
                lines.append("")

            if result.critical_elements_missing:
                lines.append("### Critical Elements Missing")
                lines.append("")
                for element in result.critical_elements_missing:
                    lines.append(f"- âŒ {element}")
                lines.append("")

            if result.link_check_results:
                broken_links = [lr for lr in result.link_check_results if not lr.ok]
                if broken_links:
                    lines.append("### Broken Links")
                    lines.append("")
                    for link in broken_links:
                        status_str = f"HTTP {link.status}" if link.status else link.error
                        external_marker = " (external)" if link.is_external else ""
                        lines.append(f"- âŒ {link.url}{external_marker} - {status_str}")
                    lines.append("")

        # Dockerå›ºæœ‰ã®æƒ…å ±
        elif isinstance(result, DockerVerificationResult):
            lines.append("### Details")
            lines.append("")
            lines.append(f"- **Build Success**: {'âœ… Yes' if result.build_success else 'âŒ No'}")
            if result.image_size_mb:
                lines.append(f"- **Image Size**: {result.image_size_mb:.2f} MB")
            lines.append(
                f"- **Container Started**: {'âœ… Yes' if result.container_started else 'âŒ No'}"
            )
            lines.append(
                f"- **Health Check**: {'âœ… Passed' if result.health_check_passed else 'âŒ Failed'}"
            )
            if result.health_check_time_ms:
                lines.append(f"- **Health Check Time**: {result.health_check_time_ms:.0f} ms")
            lines.append("")

        # ã‚¨ãƒ©ãƒ¼
        if result.errors:
            lines.append("### Errors")
            lines.append("")
            for error in result.errors:
                lines.append(f"- âŒ {error}")
            lines.append("")

        # è­¦å‘Š
        if result.warnings:
            lines.append("### Warnings")
            lines.append("")
            for warning in result.warnings:
                lines.append(f"- âš ï¸ {warning}")
            lines.append("")

    return "\n".join(lines)


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="Deployment verification tool for Letter Pack Label Maker"
    )
    parser.add_argument(
        "--target",
        choices=["all", "github-pages", "docker"],
        default="all",
        help="Verification target",
    )
    parser.add_argument(
        "--config",
        type=str,
        help="Path to configuration file",
    )
    parser.add_argument(
        "--check-links-only",
        action="store_true",
        help="Only check links (GitHub Pages only)",
    )
    parser.add_argument(
        "--skip-links",
        action="store_true",
        help="Skip link checking",
    )
    parser.add_argument(
        "--output-file",
        type=str,
        help="Output report to file",
    )

    args = parser.parse_args()

    results = {}

    # GitHub Pagesæ¤œè¨¼
    if args.target in ["all", "github-pages"]:
        print("\n" + "=" * 60)
        print("GitHub Pages Verification")
        print("=" * 60 + "\n")

        verifier = GitHubPagesVerifier(args.config)
        result = await verifier.verify(
            check_links=not args.skip_links, measure_performance=not args.check_links_only
        )
        results["github-pages"] = result

    # Dockeræ¤œè¨¼
    if args.target in ["all", "docker"] and not args.check_links_only:
        print("\n" + "=" * 60)
        print("Docker Verification")
        print("=" * 60 + "\n")

        verifier = DockerVerifier(args.config)
        result = verifier.verify()
        results["docker"] = result

    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    print("\n" + "=" * 60)
    print("Verification Report")
    print("=" * 60 + "\n")

    report = generate_markdown_report(results)
    print(report)

    # ãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›
    if args.output_file:
        output_path = Path(args.output_file)
        output_path.write_text(report, encoding="utf-8")
        print(f"\nğŸ“„ Report saved to: {output_path}")

    # çµ‚äº†ã‚³ãƒ¼ãƒ‰
    has_errors = any(len(r.errors) > 0 for r in results.values())
    sys.exit(1 if has_errors else 0)


if __name__ == "__main__":
    asyncio.run(main())
